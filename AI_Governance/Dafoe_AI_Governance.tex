\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
% Set margins
\usepackage[top=2cm, left=2cm, right=2cm, bottom=2cm]{geometry}
\usepackage{enumitem}
\setlist[itemize,2]{label=$\circ$}
% Use the multicol package to set the document to two columns
\usepackage{multicol}
\setlength{\columnsep}{20pt}

% Use a readable font
\usepackage{palatino}

% Set spacing
\setlength{\parindent}{0pt} % No paragraph indentation
\setlength{\parskip}{6pt} % Add space between paragraphs


\title{A Summary of Allan Dafoe's \textit{AI Governance: Opportunity and Theory of Impact}}
\author{Angus Robinson, 20 March 2023}
\date{}

\begin{document}

% Use the multicol environment to set the document to two columns

\maketitle
\begin{multicols}{2}

\section{Overview}
This paper contains a taxonomy of different perspective on AI risk, different kinds of AI risks, and a suggestion that the correct response to this broad range of risks is a 'field-building model of research' rather than a 'product model of research' in the field of AI Governance. Find the original (from September 2020) at \href{https://www.allandafoe.com/opportunity}{https://www.allandafoe.com/opportunity}.

\section{Key Definitions}
\begin{itemize}
    \item Superintelligence perspective: Focusing on the potential for a single AI system to achieve a decisive strategic advantage, posing an existential risk.
    \item Ecology perspective: Viewing AI as an interconnected, evolving system of multiple intelligent agents interacting with each other and their environment.
    \item GPT perspective: Treating AI as a general-purpose technology, akin to electricity or the combustion engine, with broad social and economic impacts.
    \item Product model of research: A model which says that the value of research is 'primarily in producing written answers to specific questions'
    \item Field-building model of research: A model which says that the value of research is primarily in growing the field of people who care about the issues, and in improving 'insight, expertise, connections, and authority within that field'.
\end{itemize}

\section{Three kinds of risks from AI}
\begin{itemize}
    \item Misuse risks: AI used unethically, often with malicious intent.
    \item Accident risks: Unintended harms caused by AI systems.
    \item Structural risks: Social harms or unrealized benefits due to structural dynamics and limitations of existing institutions.
\end{itemize}

\section{Implications of the different perspectives}
\begin{itemize}
    \item The more we see risks from the superintelligence perspective, the more we should focus 'on the cutting edge of AI and AI Safety'.
    \begin{itemize}
        \item From an AI Governance point of view, this means improving 'culture, organization, safety expertise, insights, and infrastructure' among groups likely to develop a superintelligence.
    \end{itemize}
    \item The more we see risks from an ecology or GPT perspective, the more we need to understand and collaborate with a broader range of sociological and political fields.
    \begin{itemize}
        \item These perspectives identify some different existential risks, and they also illuminate 'existential risk factors', which are indirect causes or exacerbating factors.
    \end{itemize}
\end{itemize}

\section{Concrete Pathways to Existential Risk from GPT or Ecology Perspectives}
\begin{itemize}
    \item Nuclear Instability: Increased risk of nuclear war due to AI-related developments in sensor technology, cyberweapons, and autonomous weapons.
    \item Power Transitions, Uncertainty, and Turbulence: Technology-induced shifts in geopolitical power can lead to war, destabilization, and a decline in collective action.
    \item Inequality, Labour Displacement, Authoritarianism: Advanced AI could lead to greater inequality, unemployment, and authoritarian control, potentially locking in bad values.
    \item Epistemic Security: AI-powered mass manipulation, undermining political communities and democratic deliberation, could impair humanity's ability to shape AI's development.
    \item Value Erosion Through Competition: Intense competition could incentivize sacrificing human values in favor of competitive performance, leading to the proliferation of bad values.
\end{itemize}

\section{Prioritization and Theory of Impact}
\begin{itemize}
    \item Because of the value of each of the perspectives, Dafoe argues for a diverse portfolio of research in the field of AI Governance, and for 'a hub with dense connections to the broader communities of computer science, social science, and policymaking'.
    \begin{itemize}
        \item However, he stresses the importance of proper prioritisation, rather than working on all related fields.
    \end{itemize}
    \item Dafoe argues that the impactful decisions will likely be made by 'AI researchers, activists, public intellectuals, CEOs, generals, diplomats, or heads of state'. The role of AI Governance research should be to provide 'assests that will help those decisions to be made well'.
    \begin{itemize}
        \item These assets should include 'technical solutions; strategic insights; shared perception of risks; a more cooperative worldview; well-motivated and competent advisors; credibility, authority, and connections for those experts'.
        \item Because these assets range so broadly, he argues for a 'field-building model of research' for AI Governance, as a product model would significantly miss a large amount of possible value.
    \end{itemize}
\end{itemize}
\section{Field-building model of research}
\begin{itemize}
    \item Valuable things in a field-building model other than direct research include:
    \begin{itemize}
        \item 'bringing diverse expertise to bear on AI governance issues'; 
        \item 'otherwise improving, as a byproduct of research, AI governance researchers' competence on relevant issues'; 
        \item 'bestowing intellectual authority and prestige to individuals who have thoughtful perspectives on long-term risks from AI'; 
        \item 'growing the field by expanding the researcher network, access to relevant talent pools, improved career-pipelines, and absorptive capacity for junior talent';
        \item 'screening, training, credentialing, and placing junior researchers'.
    \end{itemize}
    \item However, due to existing structures of funding and prestige, producing good direct research may still be the most valuable way to achieve these goals.
\end{itemize}
\section{Case Study: The Problem of International Control of AI}
\begin{itemize}
    \item Intense competition in AI R\&D, particularly in the military domain, could pose substantial global risks.
    \item Writing a plan or blueprint to solve the problem many years in advance is likely to fail due to the vast space of potential scenarios.
    \item However, trying to formulate a plan can provide insight and preparation.
    \item Building competence, capacity, and credibility in advance is crucial to being in a position to formulate a plan when the time comes.
    \item This would have been true for people worrying about nuclear risks before the development of the atomic bomb.
\end{itemize}
\end{multicols}
\end{document}
