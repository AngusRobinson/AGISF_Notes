\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
% Set margins
\usepackage[top=2cm, left=2cm, right=2cm, bottom=2cm]{geometry}
\usepackage{enumitem}
\setlist[itemize,2]{label=$\circ$}
% Use the multicol package to set the document to two columns
\usepackage{multicol}
\setlength{\columnsep}{20pt}

% Use a readable font
\usepackage{palatino}

% Set spacing
\setlength{\parindent}{0pt} % No paragraph indentation
\setlength{\parskip}{6pt} % Add space between paragraphs


\title{A Summary of Part 3 of Luke Muehlhauser and Anna Salamon's \textit{Intelligence Explosion: Evidence and Import}}

\author{Summary by Angus Robinson}
\date{27 March 2023}

\begin{document}

% Use the multicol environment to set the document to two columns

\maketitle
\begin{multicols}{2}

\section{Overview}

This section (from a chapter the authors contributed to a collection called *Singularity Hypotheses*) discusses the fundamental advantages machine intelligences would have over human intelligences, and why we might expect some of these to lead to an 'Intelligence Explosion', where machines rapidly design more intelligent machines, which design more intelligent machines and so on. \\ Find the original (from 2013) at \href{https://drive.google.com/file/d/1QxMuScnYvyq-XmxYeqBRHKz7cZoOosHr/view}{https://drive.google.com/file/d/1QxMuScnYvyq-XmxYeqBRHKz7cZoOosHr/view}.

\section{Key Definitions}

\begin{itemize}
\item \textbf{Convergent instrumental goals:}  Intermediate goals that are useful for achieving almost any final goals. We might expect rational agents in general to aim for them.
\item \textbf{Utility function:} A function that assigns a value to possible outcomes (simply a formal way of stating what an agent prefers).
\end{itemize}


\section{AI Advantages}

\begin{itemize}
    \item \textbf{Increased computational resources}: Machines can use computational resources at a huge scale, allowing for much larger "brains" than humans have.
    \item \textbf{Communication speed}: Machines can process information more rapidly than biological systemsâ€”human axons carry signals at 75m/s.
    \item \textbf{Increased serial depth}: Machines can perform longer sequential processes more efficiently and precisely than the human brain, which relies on massive parallelization.
    \item \textbf{Duplicability}: Software can be easily copied, allowing for rapid population growth and the spread of new skills across the AI population.
    \item \textbf{Editability}: Digital minds are more easily editable than human minds, allowing for finessing and more precise experimentation.
    \item \textbf{Goal coordination}: AI "copy clans" can better coordinate goals, avoiding certain limitations that hinder human effectiveness.
    \item \textbf{Improved rationality}: Humans lack stable, consistent goals, but AIs would likely be better at acting in ways most likely to achieve their goals.
\end{itemize}

\section{Instrumentally Convergent Goals}
\begin{itemize}
    \item There are several goals that advanced AIs are likely to pursue, because they are useful intermediate goals for most final goals:
    \begin{itemize}
        \item \textbf{Self-preservation}: The AI needs to continue existing if it's going to achieve its goals.
        \item \textbf{Preserving final goals}: Changing final goals means they won't satisfy their current goals.
        \item \textbf{Improving rationality and intelligence}: Better reasoning and decision-making improves their ability to achieve goals.
        \item \textbf{Resource acquisition}: More resources are likely to help achieve most goals.
    \end{itemize}
\end{itemize}

\section{Intelligence Explosion}
\begin{itemize}
    \item Designing AIs that are better at AI design than us could lead to a positive feedback loop of 'self-improvement':
    \begin{itemize}
        \item This might mean rewriting their own software, or simply designing new intelligences.
    \end{itemize}
    \item AI development could be much faster than the pace of human technological innovation:
    \begin{itemize}
        \item There is still open debate over the speed and nature of this 'takeoff', as well as what the eventual result looks like.
    \end{itemize}
\end{itemize}

\section{Consequences of Machine Superintelligence}
\begin{itemize}
    \item AI surpassing human intelligence may lead to dominance within a single lifetime.
    \item They would have superior abilities across domains, putting humans in the position of lesser animals to us.
    \item Intelligence can be applied to any goal, and throughout the explosion, AIs will be motivated to preserve their goals (see above).
    \item AIs not programmed to preserve human values may incidentally destroy structures humans value, including humans themselves.
\end{itemize}

\section{Achieving a Controlled Intelligence Explosion}
\begin{itemize}
    \item We need to build "Friendly AI" with a stable, desirable utility function before AI self-improves beyond our control.
    \begin{itemize}
        \item But AIs may not have a clear 'slot' for goals.
        \item Even if they did, specifying or teaching what humans value is extremely hard.
    \end{itemize}
    \item If we were successful, Friendly AI could vastly improve human lives, enabling joyful and meaningful living.
\end{itemize}


\end{multicols}
\end{document}
